{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense,\n",
    "    LeakyReLU, ReLU\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DFIRE_ROOT = os.path.join('..', '..', 'D-Fire') \n",
    "DFIRE_TEST_ROOT = os.path.join(DFIRE_ROOT, 'test')\n",
    "DFIRE_TEST_IMAGES_DIR = os.path.join(DFIRE_TEST_ROOT, 'images')\n",
    "DFIRE_TEST_LABELS_DIR = os.path.join(DFIRE_TEST_ROOT, 'labels')\n",
    "\n",
    "\n",
    "def is_dfire_image_fire(annotation_path, fire_class_ids):\n",
    "    if not os.path.exists(annotation_path):\n",
    "        return False\n",
    "    try:\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts and len(parts) > 0:\n",
    "                    if parts[0].isdigit():\n",
    "                        class_id = int(parts[0])\n",
    "                        if class_id in fire_class_ids:\n",
    "                            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading annotation file {annotation_path}: {e}\")\n",
    "    return False\n",
    "\n",
    "def load_prep_4_cnn(data_dir, target_size=(128, 128)):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    labels_dir = os.path.join(data_dir, 'labels')\n",
    "\n",
    "    if not os.path.isdir(images_dir) or not os.path.isdir(labels_dir):\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    img_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')\n",
    "    annotation_extension = '.txt'\n",
    "    fire_class_ids = [0, 1] \n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(img_extensions)]\n",
    "    if not image_files:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        img_name_without_ext = os.path.splitext(img_name)[0]\n",
    "        annotation_path = os.path.join(labels_dir, img_name_without_ext + annotation_extension)\n",
    "        label = 1 if is_dfire_image_fire(annotation_path, fire_class_ids) else 0\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "            img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "            all_images.append(img_normalized)\n",
    "            all_labels.append(label)\n",
    "        except Exception as e: continue\n",
    "    return np.array(all_images), np.array(all_labels)\n",
    "\n",
    "def load_all_artifacts(dataset_choice):\n",
    "    print(f\"\\n--- Loading saved CNN model for {dataset_choice} dataset ---\")\n",
    "    artifacts = {}\n",
    "    try:\n",
    "        artifacts['cnn_model'] = tf.keras.models.load_model(os.path.join(MODEL_DIR, 'dfire_cnn_best_model.keras'))\n",
    "        print(f\"Loaded CNN model: dfire_cnn_best_model.keras\")\n",
    "    except Exception as e: return None\n",
    "    return artifacts\n",
    "\n",
    "def fetch_original_test_split_for_cnn(data_root, target_size=(128, 128), test_size=0.2, random_state=42):\n",
    "    print(f\"\\n--- Fetching original test split from '{data_root}' ---\")\n",
    "    all_images, all_labels = load_prep_4_cnn(data_root, target_size)\n",
    "\n",
    "    if all_images.size == 0: return None, None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        all_images, all_labels, test_size=test_size, random_state=random_state, stratify=all_labels\n",
    "    )\n",
    "    print(f\"Successfully recreated test split with {X_test.shape[0]} samples.\")\n",
    "    return X_test, y_test\n",
    "\n",
    "def preprocess_image_for_cnn(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None: return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "\n",
    "    return np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "def evaluate_folder(folder_path, artifacts):\n",
    "    print(f\"\\n--- Processing images in folder: {folder_path} using CNN ---\")\n",
    "    cnn_model = artifacts['cnn_model']\n",
    "    if cnn_model is None: return\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_predictions = []\n",
    "    processed_count = 0\n",
    "\n",
    "    if not os.path.isdir(folder_path): return\n",
    "\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    if not image_paths: return\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing folder images\"):\n",
    "        base_dir_name = os.path.basename(os.path.dirname(image_path))\n",
    "        true_label = 1 if 'fire_images' in base_dir_name.lower() else 0\n",
    "\n",
    "        img_preprocessed = preprocess_image_for_cnn(image_path)\n",
    "        if img_preprocessed is None: continue\n",
    "\n",
    "        try:\n",
    "            prediction_proba = cnn_model.predict(img_preprocessed, verbose=0)\n",
    "            prediction = (prediction_proba > 0.5).astype(int)[0][0]\n",
    "\n",
    "            all_true_labels.append(true_label)\n",
    "            all_predictions.append(prediction)\n",
    "            processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction for {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nProcessed {processed_count} images from the folder.\")\n",
    "\n",
    "    if not all_true_labels:\n",
    "        print(\"No successful predictions for folder.\")\n",
    "        return\n",
    "\n",
    "    y_true = np.array(all_true_labels)\n",
    "    y_pred = np.array(all_predictions)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n--- Performance for CNN on Folder Data ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "def process_single_image(image_path, artifacts):\n",
    "    print(f\"\\n--- Processing single image: {image_path} ---\")\n",
    "    cnn_model = artifacts['cnn_model']\n",
    "    if cnn_model is None: return\n",
    "\n",
    "    img_display = cv2.imread(image_path)\n",
    "    if img_display is None: return\n",
    "\n",
    "    base_dir_name = os.path.basename(os.path.dirname(image_path))\n",
    "    true_label_text = 'Fire' if base_dir_name.lower() == 'fire_images' else 'Non-Fire'\n",
    "    true_label_num = 1 if base_dir_name.lower() == 'fire_images' else 0\n",
    "\n",
    "    img_preprocessed = preprocess_image_for_cnn(image_path)\n",
    "    if img_preprocessed is None: return\n",
    "\n",
    "    try:\n",
    "        prediction_proba = cnn_model.predict(img_preprocessed, verbose=0)\n",
    "        prediction = (prediction_proba > 0.5).astype(int)[0][0]\n",
    "        prediction_text = \"Fire\" if prediction == 1 else \"Non-Fire\"\n",
    "        print(f\"True Label: {true_label_text} ({true_label_num})\")\n",
    "        print(f\"CNN Prediction: {prediction_text}\")\n",
    "    except Exception as e: return\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Image: {os.path.basename(image_path)}\\nTrue: {true_label_text}\\nCNN Prediction: {prediction_text}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def reproduce_original_test_results(artifacts, dataset_root):\n",
    "    print(\"\\n--- Reproducing Original Test Set Results using train_test_split ---\")\n",
    "\n",
    "    cnn_model = artifacts['cnn_model']\n",
    "    if cnn_model is None: return\n",
    "\n",
    "    X_sample_test, y_sample_test = fetch_original_test_split_for_cnn(\n",
    "        dataset_root,\n",
    "        target_size=(128, 128),\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    if X_sample_test is None or X_sample_test.size == 0: return\n",
    "\n",
    "    print(f\"\\n--- Evaluating CNN on recreated original test data ({X_sample_test.shape[0]} samples) ---\")\n",
    "    try:\n",
    "        prediction_proba = cnn_model.predict(X_sample_test, verbose=0)\n",
    "        y_pred = (prediction_proba > 0.5).astype(int).flatten()\n",
    "        accuracy = accuracy_score(y_sample_test, y_pred)\n",
    "        f1 = f1_score(y_sample_test, y_pred, zero_division=0)\n",
    "        print(f\" - CNN Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "    except Exception as e: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7768616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading saved CNN model for dfire dataset ---\n",
      "Loaded CNN model: dfire_cnn_best_model.keras\n",
      "\n",
      "--- Reproducing Original Test Set Results using train_test_split ---\n",
      "\n",
      "--- Fetching original test split from '..\\..\\data_subsets\\D-Fire\\train' ---\n",
      "Successfully recreated test split with 326 samples.\n",
      "\n",
      "--- Evaluating CNN on recreated original test data (326 samples) ---\n",
      " - CNN Accuracy: 0.7914, F1: 0.7964\n",
      "\n",
      "--- Processing images in folder: ..\\..\\data_subsets\\D-Fire\\test using CNN ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folder images: 100%|██████████| 1635/1635 [01:22<00:00, 19.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1635 images from the folder.\n",
      "\n",
      "--- Performance for CNN on Folder Data ---\n",
      "Accuracy: 0.5602\n",
      "Precision: 0.0000\n",
      "Recall (Sensitivity): 0.0000\n",
      "F1 Score: 0.0000\n",
      "Confusion Matrix:\n",
      "[[916 719]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: '..\\\\..\\\\data_subsets\\\\D-Fire\\\\test\\\\fire_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m reproduce_original_test_results(artifacts, DATA_ROOT)\n\u001b[32m      6\u001b[39m evaluate_folder(TEST_EVAL_DATA_ROOT, artifacts) \n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m fire_images_in_test_folder = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_EVAL_DATA_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfire_images\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f.lower().endswith((\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m'\u001b[39m))]\n\u001b[32m      8\u001b[39m non_fire_images_in_test_folder = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(os.path.join(TEST_EVAL_DATA_ROOT, \u001b[33m'\u001b[39m\u001b[33mnon_fire_images\u001b[39m\u001b[33m'\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m f.lower().endswith((\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m'\u001b[39m))]\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fire_images_in_test_folder:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Sistem belirtilen yolu bulamıyor: '..\\\\..\\\\data_subsets\\\\D-Fire\\\\test\\\\fire_images'"
     ]
    }
   ],
   "source": [
    "dataset_choice = 'dfire'\n",
    "artifacts = load_all_artifacts(dataset_choice)\n",
    "\n",
    "if artifacts and artifacts['cnn_model'] is not None:\n",
    "    reproduce_original_test_results(artifacts, DATA_ROOT)\n",
    "    evaluate_folder(TEST_EVAL_DATA_ROOT, artifacts) \n",
    "    fire_images_in_test_folder = [f for f in os.listdir(os.path.join(TEST_EVAL_DATA_ROOT, 'fire_images')) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    non_fire_images_in_test_folder = [f for f in os.listdir(os.path.join(TEST_EVAL_DATA_ROOT, 'non_fire_images')) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if fire_images_in_test_folder:\n",
    "        for i in range(1,10):\n",
    "            sample_fire_image = os.path.join(TEST_EVAL_DATA_ROOT, 'fire_images', fire_images_in_test_folder[i])\n",
    "            process_single_image(sample_fire_image, artifacts)\n",
    "    else:\n",
    "        print(f\"\\nNo fire images found in {os.path.join(TEST_EVAL_DATA_ROOT, 'fire_images')}. Skipping single fire image test.\")\n",
    "\n",
    "    if non_fire_images_in_test_folder:\n",
    "        for i in range(1,10):\n",
    "            sample_non_fire_image = os.path.join(TEST_EVAL_DATA_ROOT, 'non_fire_images', non_fire_images_in_test_folder[i])\n",
    "            process_single_image(sample_non_fire_image, artifacts)\n",
    "            \n",
    "    else:\n",
    "        print(f\"\\nNo non-fire images found in {os.path.join(TEST_EVAL_DATA_ROOT, 'non_fire_images')}. Skipping single non-fire image test.\")\n",
    "else:\n",
    "    print(\"Failed to load CNN model. Cannot proceed with testing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
