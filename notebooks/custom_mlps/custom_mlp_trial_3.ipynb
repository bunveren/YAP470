{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d249c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kütüphaneler yüklendi.\n",
      "Yardımcı sınıf ve fonksiyonlar tanımlandı.\n",
      "Veri seti oluşturuldu. Eğitim seti boyutu: (400, 100), Test seti boyutu: (100, 100)\n",
      "\n",
      "Eğitim başlıyor...\n",
      "\n",
      "Bir hata oluştu: 'super' object has no attribute '__sklearn_tags__'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Temp\\ipykernel_18296\\967924475.py\", line 164, in <module>\n",
      "    search_cv.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py\", line 933, in fit\n",
      "    cv_orig = check_cv(self.cv, y, classifier=is_classifier(estimator))\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1237, in is_classifier\n",
      "    return get_tags(estimator).estimator_type == \"classifier\"\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\BerenÜnveren\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 540, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n"
     ]
    }
   ],
   "source": [
    "# Gerekli Kütüphaneler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU, Input\n",
    "\n",
    "from scikeras.wrappers import BaseWrapper\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Kütüphaneler yüklendi.\")\n",
    "\n",
    "class KerasMLPClassifier(BaseWrapper, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=None,\n",
    "        optimizer=\"adam\",\n",
    "        optimizer__learning_rate=0.001,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=None,\n",
    "        callbacks=None,\n",
    "        validation_split=0.2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer__learning_rate = optimizer__learning_rate\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.callbacks = callbacks\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "    def _fit(self, X, y, sample_weight=None, warm_start=False):\n",
    "        self.model_ = self.build_fn(meta=self._get_meta_params())\n",
    "        optimizer_instance = self.optimizer(learning_rate=self.optimizer__learning_rate)\n",
    "        self.model_.compile(\n",
    "            optimizer=optimizer_instance,\n",
    "            loss=self.loss,\n",
    "            metrics=self.metrics,\n",
    "        )\n",
    "        \n",
    "        self.history_ = self.model_.fit(\n",
    "            X,\n",
    "            y,\n",
    "            sample_weight=sample_weight,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=self.validation_split,\n",
    "            callbacks=self.callbacks,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_proba = self.predict_proba(X)\n",
    "        return (y_proba > 0.5).astype(\"int32\")\n",
    "    \n",
    "    def _more_tags(self):\n",
    "        return {\"binary_only\": True}\n",
    "\n",
    "def create_custom_mlp(hidden_layer_configs=(50, 50),\n",
    "                        dropout_rate=0.3,\n",
    "                        activation='leaky_relu',\n",
    "                        meta=None):\n",
    "    if meta is None:\n",
    "        raise ValueError(\"meta parametresi eksik.\")\n",
    "        \n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    layer1_neurons, layer2_neurons = hidden_layer_configs\n",
    "    \n",
    "    model = Sequential(name=\"custom_MLP_trial\")\n",
    "    model.add(Input(shape=(n_features_in,)))\n",
    "    \n",
    "    model.add(Dense(layer1_neurons))\n",
    "    model.add(BatchNormalization())\n",
    "    if activation == 'leaky_relu': model.add(LeakyReLU(alpha=0.1))\n",
    "    else: model.add(tf.keras.layers.ReLU())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    if layer2_neurons is not None and layer2_neurons > 0:\n",
    "        model.add(Dense(layer2_neurons))\n",
    "        model.add(BatchNormalization())\n",
    "        if activation == 'leaky_relu': model.add(LeakyReLU(alpha=0.1))\n",
    "        else: model.add(tf.keras.layers.ReLU())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_features=100, n_informative=50,\n",
    "        n_redundant=20, n_classes=2, random_state=42\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"Veri seti oluşturuldu. Eğitim seti boyutu: {X_train.shape}, Test seti boyutu: {X_test.shape}\")\n",
    "\n",
    "    keras_estimator = KerasMLPClassifier(\n",
    "        model=create_custom_mlp,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, restore_best_weights=True)]\n",
    "    )\n",
    "    param_distributions = {\n",
    "        'model__hidden_layer_configs': [(64, 32), (128, 64), (100, None)],\n",
    "        'model__dropout_rate': [0.2, 0.4],\n",
    "        'model__activation': ['relu', 'leaky_relu'],\n",
    "        'optimizer__learning_rate': [0.001, 0.005]\n",
    "    }\n",
    "        \n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    search_cv = RandomizedSearchCV(\n",
    "        estimator=keras_estimator,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=4,\n",
    "        cv=cv_strategy,\n",
    "        scoring='f1',\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        search_cv.fit(X_train, y_train)\n",
    "        print(f\"En iyi F1 skoru (CV): {search_cv.best_score_:.4f}\")\n",
    "        print(\"En iyi parametreler:\")\n",
    "        print(search_cv.best_params_)\n",
    "        \n",
    "        best_model = search_cv.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"\\nTest seti üzerindeki F1 Skoru: {test_f1:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nhata: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
