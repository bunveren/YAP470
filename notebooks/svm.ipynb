{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e298e0",
   "metadata": {},
   "source": [
    "DATA PREP \n",
    "1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "import cv2, os, numpy as np, time, joblib\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "# i asked ai about this and it suggested me this type of kfold. \n",
    "# i will provide some info abt it in the latter markdown\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff92f0",
   "metadata": {},
   "source": [
    "-> https://aistudio.google.com/prompts/new_chat \n",
    "    Why StratifiedKFold instead of standard KFold?\n",
    "\n",
    "    Both KFold and StratifiedKFold are used for cross-validation. Cross-validation is a technique used during training (especially for hyperparameter tuning with GridSearchCV or RandomizedSearchCV) to get a more reliable estimate of your model's performance than a single train/validation split.\n",
    "\n",
    "        KFold: This splits the dataset into k contiguous folds (subsets) without shuffling by default. If you shuffle (shuffle=True), it randomly divides the data into k folds. Each fold is roughly the same size.\n",
    "\n",
    "        StratifiedKFold: This is similar to KFold, but it makes the splits by preserving the percentage of samples for each class. If your overall dataset has 75% class A and 25% class B, StratifiedKFold will ensure that each of the k folds also has approximately 75% class A and 25% class B samples. Each fold is roughly the same size and has a representative class distribution.\n",
    "\n",
    "        Why StratifiedKFold for classification (especially with imbalance)?\n",
    "\n",
    "            Reliable Evaluation: In classification problems, especially with imbalanced datasets (like yours, where Fire=1 is the minority class at ~24% in the Kaggle data), a standard KFold might accidentally create one or more folds that have very few or even zero samples from the minority class. If a fold used for validation has no fire images, the model's performance (like Recall or F1-score) on that fold will be undefined or misleadingly high/low.\n",
    "\n",
    "            Robust Training: Similarly, if a fold used for training has very few fire images, the model might not learn to identify the minority class effectively from that fold.\n",
    "\n",
    "            StratifiedKFold avoids this by ensuring each fold is a miniature version of the overall dataset's class distribution. This means the performance metric calculated on each fold is a more reliable estimate, and the average metric across all folds (which GridSearchCV uses) is a better overall performance estimate for your hyperparameter tuning.\n",
    "\n",
    "    In your project's context: Your Kaggle dataset has class imbalance (755 fire, 244 non-fire). Using StratifiedKFold for the cross-validation within GridSearchCV ensures that when GridSearchCV tests different hyperparameter combinations, it gets a stable and realistic F1-score (or whichever scoring metric you choose) for each combination by evaluating on folds that accurately represent the imbalance you expect the model to face. If you used standard KFold, the F1-scores from different folds could vary wildly just due to random chance in how the minority class samples were distributed across folds.\n",
    "\n",
    "\n",
    "\n",
    "-> https://www.datacamp.com/tutorial/k-fold-cross-validation\n",
    "Stratified Group K-Fold Cross-Validation \tPrimarily classification with grouped data \tCombines stratification and group integrity, ensuring that groups are not split across folds. \tGreat for grouped and imbalanced datasets to maintain both class and group integrity.\n",
    "just before conclusion there is a table for kfold types, i took the info from there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c396c",
   "metadata": {},
   "source": [
    "2. Loading & Extracting Features\n",
    "TODO: pca yi unuttum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e490c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prep_img(data_root, target_size, \n",
    "    color_spaces=['bgr', 'hsv', 'ycbcr'], normalize=1):\n",
    "    processed_data = {cs: [] for cs in color_spaces + ['gray']}\n",
    "    labels = []\n",
    "    class_dirs = {'fire_images': 1, 'non_fire_images': 0}\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png']\n",
    "    \n",
    "    total_images_processed = 0\n",
    "    total_images_skipped = 0\n",
    "    for class_name, label in class_dirs.items():\n",
    "        class_dir_path = os.path.join(data_root, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_dir_path): continue\n",
    "        \n",
    "        all_files = os.listdir(class_dir_path)\n",
    "        image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in img_extensions]\n",
    "\n",
    "        if not image_files: continue\n",
    "        \n",
    "        for filename in tqdm(image_files, desc=f\"Processing {class_name}\"):\n",
    "            file_path = os.path.join(class_dir_path, filename)\n",
    "            img_bgr = cv2.imread(file_path)\n",
    "\n",
    "            if img_bgr is None:\n",
    "                total_images_skipped += 1\n",
    "                continue\n",
    "\n",
    "            img_resized = cv2.resize(img_bgr, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "            if normalize: img_resized = img_resized.astype(np.float32) / 255.0\n",
    "\n",
    "            img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "            processed_data['gray'].append(img_gray)\n",
    "\n",
    "            if 'bgr' in color_spaces:\n",
    "                 processed_data['bgr'].append(img_resized)\n",
    "            if 'hsv' in color_spaces:\n",
    "                img_hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
    "                processed_data['hsv'].append(img_hsv)\n",
    "            if 'ycbcr' in color_spaces:\n",
    "                img_ycbcr = cv2.cvtColor(img_resized, cv2.COLOR_BGR2YCrCb)\n",
    "                processed_data['ycbcr'].append(img_ycbcr)\n",
    "\n",
    "            labels.append(label)\n",
    "            total_images_processed += 1\n",
    "\n",
    "        print(f\"\\ntoplam islenen: {total_images_processed} atlanan: {total_images_skipped}\")\n",
    "    \n",
    "    output_dtype = np.float32 if normalize else np.uint8\n",
    "    numpy_data = {}\n",
    "    for cs, data_list in processed_data.items():\n",
    "        if data_list:\n",
    "             numpy_data[cs] = np.array(data_list)\n",
    "        else:\n",
    "             if cs == 'gray':\n",
    "                  numpy_data[cs] = np.array([], dtype=output_dtype).reshape(0, target_size[1], target_size[0])\n",
    "             else:\n",
    "                  numpy_data[cs] = np.array([], dtype=output_dtype).reshape(0, target_size[1], target_size[0], 3)\n",
    "\n",
    "    numpy_data['labels'] = np.array(labels)\n",
    "    return numpy_data    \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2decd0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histograms(img_processed, color_space, bins):\n",
    "    histograms = []\n",
    "    if color_space == 'hsv':\n",
    "        if img_processed.dtype == np.float32:\n",
    "            hist_h = cv2.calcHist([img_processed], [0], None, [bins], [0, 360])\n",
    "            hist_s = cv2.calcHist([img_processed], [1], None, [bins], [0, 1])\n",
    "            histograms.extend([hist_h.flatten(), hist_s.flatten()]) \n",
    "        elif img_processed.dtype == np.uint8:\n",
    "            hist_h = cv2.calcHist([img_processed], [0], None, [bins], [0, 180])\n",
    "            hist_s = cv2.calcHist([img_processed], [1], None, [bins], [0, 256])\n",
    "            histograms.extend([hist_h.flatten(), hist_s.flatten()]) \n",
    "    elif color_space == 'ycbcr':\n",
    "        if img_processed.dtype == np.float32:\n",
    "            hist_y = cv2.calcHist([img_processed], [0], None, [bins], [0, 1])\n",
    "            hist_cb = cv2.calcHist([img_processed], [1], None, [bins], [-0.5, 0.5])\n",
    "            hist_cr = cv2.calcHist([img_processed], [2], None, [bins], [-0.5, 0.5])\n",
    "            histograms.extend([hist_y.flatten(), hist_cb.flatten(), hist_cr.flatten()])\n",
    "        elif img_processed.dtype == np.uint8:\n",
    "            hist_y = cv2.calcHist([img_processed], [0], None, [bins], [0, 256])\n",
    "            hist_cb = cv2.calcHist([img_processed], [1], None, [bins], [0, 256])\n",
    "            hist_cr = cv2.calcHist([img_processed], [2], None, [bins], [0, 256])\n",
    "            histograms.extend([hist_y.flatten(), hist_cb.flatten(), hist_cr.flatten()])\n",
    "\n",
    "    if histograms: return np.concatenate(histograms)\n",
    "    else: return np.array([]) \n",
    "\n",
    "def extract_lbp_features(img_gray, radius, n_points, method):\n",
    "    if n_points is None:\n",
    "        n_points = 8 * radius\n",
    "    lbp_image = local_binary_pattern(img_gray, n_points, radius, method=method)\n",
    "    if method == 'uniform':\n",
    "        n_bins = n_points + 2\n",
    "    else:\n",
    "         n_bins = int(lbp_image.max() + 1)\n",
    "    lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "    lbp_hist = lbp_hist.astype(np.float32)\n",
    "    if lbp_hist.sum() > 0:\n",
    "        lbp_hist /= lbp_hist.sum()\n",
    "    return lbp_hist.flatten()\n",
    "\n",
    "def extract_hog_features(img_gray, orientations, pixels_per_cell, cells_per_block, block_norm):\n",
    "    hog_features = hog(img_gray, orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm=block_norm,\n",
    "                       visualize=False, feature_vector=True)\n",
    "    return hog_features.flatten() \n",
    "\n",
    "def combine_features(img_dict, feature_params):\n",
    "    all_features = []\n",
    "    if 'hsv' in img_dict:\n",
    "        hsv_hist = extract_color_histograms(img_dict['hsv'], 'hsv', bins=feature_params.get('hist_bins', 100))\n",
    "        if hsv_hist.size > 0:\n",
    "            all_features.append(hsv_hist)\n",
    "    if 'ycbcr' in img_dict:\n",
    "         ycbcr_hist = extract_color_histograms(img_dict['ycbcr'], 'ycbcr', bins=feature_params.get('hist_bins', 100))\n",
    "         if ycbcr_hist.size > 0:\n",
    "              all_features.append(ycbcr_hist)\n",
    "\n",
    "    if 'gray' in img_dict:\n",
    "        img_gray_processed = img_dict['gray'] \n",
    "\n",
    "        lbp_features = extract_lbp_features(img_gray_processed,\n",
    "                                            radius=feature_params.get('lbp_radius', 3),\n",
    "                                            n_points=feature_params.get('lbp_n_points', None),\n",
    "                                            method=feature_params.get('lbp_method', 'uniform'))\n",
    "        if lbp_features.size > 0:\n",
    "             all_features.append(lbp_features)\n",
    "\n",
    "        hog_features = extract_hog_features(img_gray_processed,\n",
    "                                           orientations=feature_params.get('hog_orientations', 9),\n",
    "                                           pixels_per_cell=feature_params.get('hog_pixels_per_cell', (8, 8)),\n",
    "                                           cells_per_block=feature_params.get('hog_cells_per_block', (2, 2)),\n",
    "                                           block_norm=feature_params.get('hog_block_norm', 'L2-Hys'))\n",
    "        if hog_features.size > 0:\n",
    "             all_features.append(hog_features)\n",
    "\n",
    "    if all_features:\n",
    "        combined_vector = np.concatenate(all_features)\n",
    "        return combined_vector\n",
    "    else:\n",
    "        return np.array([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0803a",
   "metadata": {},
   "source": [
    "3. Data Split & Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811590fe",
   "metadata": {},
   "source": [
    "4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badab83",
   "metadata": {},
   "source": [
    "5. Model Eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
